---
title: "Fence expansion prelinary report"
author: "Trevor Davies"
date: '2022-03-01'
output:
  #bookdown::html_document2: default
  bookdown::pdf_document2: default
bibliography: references.bib  
link-citations: yes
linkcolor: blue
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/american-fisheries-society.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(lubridate)
library(bookdown)
library(splines)
library(rstan)
#https://bookdown.org/yihui/rmarkdown-cookbook/
```

# Introduction and Project Scope

The Babine river has a salmonine enumeration facility encounters all five Pacific salmon species in addition to steelhead.  The primary goal of the facility is to enumerate sockeye, chinook and pink salmon whose runs span from mid-July and are generally over by mid-October.  The Coho run frequently continues outside the historical monitoring period (i.e after October 15th of each year) and consequently suffers from truncated and incomplete counts.  Previous to the work here, Holtby (2002) estimated missing run days by using data from years that had complete counts to estimate the "missing proportion".  This approach is limited as it does not make use of anxillary information that may be useful to account for within-year run timing variability.

Here, I employ two approaches to obtain robust estimates of escapement for the Babine Coho salmon fish passage and compare those results to Holtby (2002; need ref).  First, similar to @cite-walsworth2015 I employ a Bayesian hierarchical model that uses environmental co-variates to obtain estimates of total run size  for Coho at the Babine fishway from 1950 through 2021.  Second, if time allows, I will employ a novel hierarchical Generalized Additive Model (GAM) that also uses environmental data to obtain coho passage estimates. I compare and contrast these three methods.


```{r read_data,echo=FALSE}
# Code below reads in data from excel and changes the matrix into a data frame, into long format, fixes dates and adds julian day.
data1 <- read_excel("../Data/DFO/Babine Coho Daily 1946-2021.xlsx", sheet="Coho",  col_names = T )  %>% 
  gather("Year","Count",-Date) %>% mutate(Year= as.numeric(Year),day=day(Date),month=month(Date),julian=yday(Date), Date=ymd(paste(Year,month,day)),fake.date=as_date(julian,origin="2021-01-01")) %>% 
  filter(!is.na(Count))

### identify common starting data
first_fish <- data1 %>%  
  group_by(julian) %>%
  summarize(total_julian = sum(Count, na.rm = TRUE)) %>%
  filter(total_julian !=0) %>% slice(1)  # in all datasets first fish was never before julian 199

complete_years <- c(1950,1952,1953,1957,1976,1977, 1979,1985, 1989, 1991, 1994, 1995, 1996, 1997, 1998, 1999, 2021)
base_yrs <- c(1950,1952,1957,	1976,	1977,	1979,	1985,	1989,	1995,	1998)

```

# Data Description
The data used here spans from `r min(data1$Year)` through `r max(data1$Year)`.

The earliest day in data used in this projects begins in `r format(as.Date(first_fish$julian, origin=as.Date("2021-01-01")),"%m-%d")` and complete counts are assumed to be `r complete_years`.


# Modelling Approach

Here we will be evaluating and comparing three methods of total escapement estimation.  First, is using historical correction method 

Here I will describe Holtby (2002)



```{r ref-years,fig.cap="Example of complete run years.  Fitted line is done vie a generalized additive model (GAM)", echo=FALSE, eval = TRUE}
#x1 <- data1 %>% filter(Year %in% complete_years, julian > first_fish$julian)
#ggplot(data=x1, aes(x=julian,y=Count)) + geom_bar(stat='identity') + facet_wrap(.~ Year,ncol = 3, scales = "free_y") +theme_bw()

#ggplot(x1, aes(x = julian, y = Count, fill = as.character(Year))) + geom_ribbon(stat = "smooth", aes(ymin = 0, ymax = ..y..), colour="black",alpha = .2,  method = "gam", se=FALSE, formula = y ~ s(x, k = 60))


x2 <- data1 %>% filter(Year %in% base_yrs[1:4], julian > first_fish$julian)

ggplot(x2, aes(x = julian, y = Count)) + geom_point(alpha=.75) + geom_segment(aes(x = julian,xend=julian,y=0,yend=Count),alpha=0.75) + geom_ribbon(stat = "smooth", aes(ymin = 0, ymax = ..y..), colour="black",alpha = .2,  method = "gam", se=FALSE, formula = y ~ s(x, k = 40)) +theme_bw() + facet_wrap(.~ Year,ncol = 2) 
```



See Figure \@ref(fig:ref-years). 

# Methods 
## Bayesian Hierarchical model

Here, I will be using the migration timing model as described in @cite-walsworth2015.  This approach assumes a unimodal distribution of migrations timing and is decribed by the following equations.  The following is to fit the model to a single year:

\begin{equation}
E_i = r e^{[\frac{-(d_i - p)^2}{\sigma^2}]} / \psi
\end{equation} 

where $E_i$ is the expected daily coho count at the fence on day $i$; $d_i$ is the numeric day that count was recorded ($i$); $r$ is the total escapement for that year; $p$ is the day in which peak escapement occured; $\$sigma$ is the standard deviation in when the peak run day was observed; and $psi$ is a normalizing constant so that:

\begin{equation}
\sum_{i=1}^{n} \{e^{[\frac{-(d_i - p)^2}{\sigma^2}]}]\} / \psi = 1
\end{equation} 

Ultimately, the normalizing constant ensures that the total escapement parameter $r$ is proportionally allocated to each day of the run.

## Reference Approach
Holtby (2002) developed a method to estimate missing years and truncated data series by.... 


## Genearlize Additive Model (GAM)
The generalized additive modelling (GAM) approach is where you use smoothed functions of data to estimate relationships between predictor and the response.  

We can write the GAM structure as:
\begin{equation}
g(E(Y))=\alpha + s_1(x_1)
\end{equation}

where $Y$ is the dependent variable (i.e., the daily fish passage), $E(Y)$ denotes the expected value, and $g(Y)$ denotes the link function that links the expected value to the predictor variables $x_1,â€¦,x_p$.

The term $s_1(x_1)$ denote smooth, nonparametric functions. Note that, in the context of regression models, the terminology nonparametric means that the shape of predictor functions are fully determined by the data as opposed to parametric functions that are defined by a typically small set of parameters.




# References

<div id="refs"></div>

# Appendix A: STAN {-} 
Stan is a Bayesian modelling and programming language that can be called from R [@cite-R] via the rstan package [@cite-stan]. Following is the model code  

## Appendix A-1: Naive model
1. Naive model: simulated data
2. Naive model: single year 
3. Naive model: multiple years
4. Naive model: Hierarchical
5. Informed model: Hierarchical with environmental covariates 



### Naive model: simulated data
First as a proof of concept I generated simulated data and fit the model to ensure I can recapture the parameters. The model was able to successfully recapture pre-defined parameter estimates (with noise added).  The total run size (after adding error; $r$) was 10,951.

```{r simtable1, echo=FALSE}
table1 <- readRDS('naive/tables/est_sim_table.rds')
knitr::kable(table1, caption = "Recapture of parameters from simulated data", digits = 1)
```

Below is the model fit.

![Model fit to simulated run using parameters in TableTable \@ref(tab:simtable1).  Error was added via a lognormal distribution with standard deviation of 0.2 so total run size was 10,951.](naive/plots/naive_sim.pdf)

### Next steps
1. Add indexing to allow multiple years to be fit that have ragged arrays.
2. Add hierarchical structure.

### Naive model: single year 
### Naive model: multiple years
### Naive model: Hierarchical
### Informed model: Hierarchical with environmental covariates 



## Appendix A-2: Final model that includes environmental covariates

Here, I will give a brief example of how stan works in R by demonstrating how to run  a bayesisn generalized linear model with normal error structure (equivalent to a least-squares regression).
https://mc-stan.org/docs/2_18/stan-users-guide/hierarchical-logistic-regression.html
https://mc-stan.org/cmdstanr/articles/r-markdown.html

# Appendix B: Comparison with Reference {-} 



# Appendix C: Generalized Additive Modelling (GAM)  {-} 

## Appendix C-1: Naive model with simulated data
First model uses nothing but day-of-year as a predictor of fish passage.



```{r GAMsim,fig.cap="GAM fit to simulated data", echo=FALSE, eval = TRUE}
#https://multithreaded.stitchfix.com/blog/2015/07/30/gam/
r <- 10000  # total run
p <- 250  # peak escapement DAY
sigma <- 10 # error
d <- 200:300 #days

set.seed(111)
psi <- sum(exp(-((d-p)^2)/(2*sigma^2)))
run <- r*(exp(-((d-p)^2)/(2*sigma^2)))/psi
run_error <- rlnorm(length(run),log(run),0.2)

single_sim <- data.frame(julian=d,Count=round(run_error,0))

ggplot(single_sim, aes(x = julian, y = Count)) + geom_segment(aes(x = julian,xend=julian,y=0,yend=Count),alpha=0.75) + geom_ribbon(stat = "smooth", aes(ymin = 0, ymax = ..y..), colour="black",alpha = .2,  method = "gam", se=FALSE, formula = y ~ s(x, k = 20)) +theme_bw() 
```




## Appendix C-2: Final model that includes environmental covariates

The advantage of a hierarchical structure is that it allows the data from all year to inform each other to ideally obtain better estimates for each years parameters.  Hyper priors are quite important particularly on sigma as(see 53 min of video - use half cauchy for sigma )

https://peerj.com/articles/6876/
https://en.wikipedia.org/wiki/Generalized_additive_model


\newpage 

# Model code
## STAN Code for single year

```stan
data {
  int N;        // Number of observations (101)
  int y[N];     // Vector of observations
  vector[N] x;  // Vector of DOY
}
 
// The parameters we are going to estimate in our model
parameters {
  real<lower=0> p;  // day of peak escapement  
  real log_r;       // total escapement 
  real<lower=0, upper=15> sigma; //standard deviation in arrival timing
  real<lower=0> reciprocal_phi;  // over dispersion parameter for the negative binomial 
}
 
transformed parameters{
  real r=exp(log_r);  
  real phi;
  vector[N] log_phi2;
  vector[N] c_hat;     // expected values of the model
  phi = 1. / reciprocal_phi;
//// These are vectorized
  log_phi2 = -square(x-p) / (2*square(sigma));
  c_hat = log_r + log_phi2 - log_sum_exp(log_phi2);
}

 model {
  //Priors
  reciprocal_phi ~ cauchy(0., 3);
  log_r ~ uniform(1,20);
  sigma ~ cauchy(0., 3);
  p ~ uniform(50, 330);
  // MODEL 
  y ~ neg_binomial_2_log(c_hat, phi);
}

generated quantities {
  vector[N] mu;
  //vector[N] log_lik;
  vector[N] y_rep;
  mu = exp(c_hat);
for (i in 1:N) {
  //log_lik[i] = neg_binomial_2_log_lpmf(y[i] | c_hat[i], phi);
  y_rep[i] = neg_binomial_2_log_rng(c_hat[i], phi);
  }
}
```

